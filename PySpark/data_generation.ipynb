{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d38f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, lit, floor, rand, when, from_unixtime\n",
    "from pyspark.sql.types import StructType, StructField, LongType, StringType, TimestampType, DoubleType\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"generate_large_orders\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"400\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Parameters you can change\n",
    "NUM_ROWS = 100_000_000  # 100 million\n",
    "TARGET_PARTITIONS = 400  # roughly num_cores * 3\n",
    "OUTPUT_PATH = \"/data/test/orders_parquet\"\n",
    "\n",
    "# 1) create a base range DF â€” this is very fast and parallel\n",
    "base = spark.range(0, NUM_ROWS, numPartitions=TARGET_PARTITIONS).toDF('idx')\n",
    "\n",
    "# 2) derive columns from idx (deterministic, reproducible)\n",
    "orders = (\n",
    "    base\n",
    "    .withColumn('order_id', col('idx') + 1)\n",
    "    .withColumn('user_id', (col('idx') % 10_000_000) + 1)  # 10M unique users\n",
    "    .withColumn('product_id', (col('idx') % 1_000_000) + 1)  # 1M products\n",
    "    .withColumn('price', (floor(rand(seed=42) * 10000) / 100).cast('double'))\n",
    "    .withColumn('currency', when((col('idx') % 3) == 0, lit('USD')).when((col('idx') % 3) == 1, lit('EUR')).otherwise(lit('INR')))\n",
    "    .withColumn('country', expr(\"CASE WHEN idx % 50 = 0 THEN 'US' WHEN idx % 50 = 1 THEN 'IN' WHEN idx % 50 = 2 THEN 'DE' ELSE 'GB' END\"))\n",
    "    .withColumn('payment_method', expr(\"CASE WHEN idx % 6 = 0 THEN 'card' WHEN idx % 6 = 1 THEN 'paypal' WHEN idx % 6 = 2 THEN 'upi' ELSE 'netbanking' END\"))\n",
    "    .withColumn('event_time', from_unixtime((col('idx') % (86400 * 365)) + 1609459200).cast('timestamp'))  # spread over 2021\n",
    "    .select('order_id','user_id','event_time','product_id','price','currency','country','payment_method')\n",
    ")\n",
    "\n",
    "# 3) Optional: introduce skew by duplicating some user ranges (example: heavy users)\n",
    "heavy_users = orders.filter((col('user_id') >= 1) & (col('user_id') <= 1000))\n",
    "# write full orders dataset\n",
    "orders.repartition(TARGET_PARTITIONS, col('country')) \\\n",
    "      .write.mode('overwrite') \\\n",
    "      .partitionBy('country') \\\n",
    "      .parquet(OUTPUT_PATH)\n",
    "\n",
    "print('Done writing to', OUTPUT_PATH)\n",
    "\n",
    "# Stop Spark"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
