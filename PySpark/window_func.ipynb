{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3885a22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+----------+------+------------+-----------------+\n",
      "|employee_id| name|department|salary|joining_date|performance_score|\n",
      "+-----------+-----+----------+------+------------+-----------------+\n",
      "|          1|Alice|     Sales| 72000|  2018-01-15|              3.8|\n",
      "|          2|  Bob|     Sales| 68000|  2019-03-12|              4.1|\n",
      "|          3|Carol|     Sales| 72000|  2020-06-05|              4.1|\n",
      "|          4|David|        IT| 98000|  2017-11-01|              4.9|\n",
      "|          5|  Eva|        IT|102000|  2018-12-24|              4.7|\n",
      "+-----------+-----+----------+------+------------+-----------------+\n",
      "only showing top 5 rows\n",
      "+--------+--------+------+----------+------+\n",
      "|order_id|customer|region|order_date|amount|\n",
      "+--------+--------+------+----------+------+\n",
      "|    1001|   Alice| North|2021-01-02| 250.0|\n",
      "|    1002|     Bob| North|2021-01-05| 120.0|\n",
      "|    1003|   Carol| South|2021-01-03| 300.0|\n",
      "|    1004|   David|  East|2021-01-07| 450.0|\n",
      "|    1005|     Eva|  East|2021-01-08| 200.0|\n",
      "+--------+--------+------+----------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"WindowExamples\").getOrCreate()\n",
    "\n",
    "emp = spark.read.csv(\"employee.csv\", header=True, inferSchema=True)\n",
    "orders = spark.read.csv(\"orders.csv\", header=True, inferSchema=True)\n",
    "\n",
    "emp.show(5)\n",
    "orders.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ede851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, rank, dense_rank, row_number, lag, lead, sum as _sum, avg as _avg\n",
    "from pyspark.sql.functions import min as _min, max as _max\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "from pyspark.sql.types import TimestampType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_salary_range = Window.partitionBy(\"department\").orderBy(col(\"salary\").desc(), col(\"joining_date\").asc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "520fc4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----------+------+-------+\n",
      "|employee_id|  name|department|salary|row_num|\n",
      "+-----------+------+----------+------+-------+\n",
      "|         13|  Maya|   Finance|112000|      1|\n",
      "|         15|Olivia|   Finance|112000|      2|\n",
      "|         14|  Nate|   Finance|108000|      3|\n",
      "|          8|  Hank|        HR| 66000|      1|\n",
      "|         18|  Rita|        HR| 66000|      2|\n",
      "|          7| Grace|        HR| 64000|      3|\n",
      "|          9|   Ivy|        HR| 64000|      4|\n",
      "|          5|   Eva|        IT|102000|      1|\n",
      "|         17| Quinn|        IT|102000|      2|\n",
      "|          4| David|        IT| 98000|      3|\n",
      "+-----------+------+----------+------+-------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "emp_rownum = emp.withColumn(\"row_num\", row_number().over(dept_salary_range))\n",
    "emp_rownum.select(\"employee_id\",\"name\",\"department\",\"salary\",\"row_num\").orderBy(\"department\",\"row_num\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "256adefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----------+------+---+----+\n",
      "|employee_id|  name|department|salary|rnk|drnk|\n",
      "+-----------+------+----------+------+---+----+\n",
      "|         13|  Maya|   Finance|112000|  1|   1|\n",
      "|         15|Olivia|   Finance|112000|  1|   1|\n",
      "|         14|  Nate|   Finance|108000|  3|   2|\n",
      "|          8|  Hank|        HR| 66000|  1|   1|\n",
      "|         18|  Rita|        HR| 66000|  1|   1|\n",
      "|          7| Grace|        HR| 64000|  3|   2|\n",
      "|          9|   Ivy|        HR| 64000|  3|   2|\n",
      "|          5|   Eva|        IT|102000|  1|   1|\n",
      "|         17| Quinn|        IT|102000|  1|   1|\n",
      "|          4| David|        IT| 98000|  3|   2|\n",
      "|          6| Frank|        IT| 98000|  3|   2|\n",
      "|         19|   Sam| Marketing| 92000|  1|   1|\n",
      "+-----------+------+----------+------+---+----+\n",
      "only showing top 12 rows\n"
     ]
    }
   ],
   "source": [
    "emp_rank = emp.withColumn(\"rnk\", rank().over(dept_salary_range)) \\\n",
    "              .withColumn(\"drnk\", dense_rank().over(dept_salary_range))\n",
    "\n",
    "emp_rank.select(\"employee_id\",\"name\",\"department\",\"salary\",\"rnk\",\"drnk\").orderBy(\"department\",\"rnk\").show(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "661878d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------+------+-----------+-----------+\n",
      "|  name|department|joining_date|salary|prev_salary|next_salary|\n",
      "+------+----------+------------+------+-----------+-----------+\n",
      "|  Maya|   Finance|  2016-01-10|112000|       NULL|     108000|\n",
      "|  Nate|   Finance|  2018-10-12|108000|     112000|     112000|\n",
      "|Olivia|   Finance|  2019-11-19|112000|     108000|       NULL|\n",
      "| Grace|        HR|  2016-08-30| 64000|       NULL|      66000|\n",
      "|  Hank|        HR|  2018-05-20| 66000|      64000|      64000|\n",
      "|   Ivy|        HR|  2020-02-14| 64000|      66000|      66000|\n",
      "|  Rita|        HR|  2021-09-01| 66000|      64000|       NULL|\n",
      "| David|        IT|  2017-11-01| 98000|       NULL|     102000|\n",
      "|   Eva|        IT|  2018-12-24|102000|      98000|      98000|\n",
      "| Frank|        IT|  2019-04-10| 98000|     102000|     102000|\n",
      "| Quinn|        IT|  2021-06-18|102000|      98000|       NULL|\n",
      "|   Sam| Marketing|  2016-05-05| 92000|       NULL|      89000|\n",
      "+------+----------+------------+------+-----------+-----------+\n",
      "only showing top 12 rows\n"
     ]
    }
   ],
   "source": [
    "dept_dates = Window.partitionBy(\"department\").orderBy(col(\"joining_date\").asc())\n",
    "\n",
    "emp_laglead = emp.withColumn(\"prev_salary\", lag(\"salary\", 1).over(dept_dates))\\\n",
    "                 .withColumn(\"next_salary\", lead(\"salary\", 1).over(dept_dates))\n",
    "\n",
    "emp_laglead.select(\"name\", \"department\", \"joining_date\", \"salary\", \"prev_salary\", \"next_salary\")\\\n",
    "           .orderBy(\"department\", \"joining_date\").show(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63e29b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----------+------------+------+-----------------+\n",
      "|employee_id|  name|department|joining_date|salary|cumulative_salary|\n",
      "+-----------+------+----------+------------+------+-----------------+\n",
      "|         13|  Maya|   Finance|  2016-01-10|112000|           112000|\n",
      "|         14|  Nate|   Finance|  2018-10-12|108000|           220000|\n",
      "|         15|Olivia|   Finance|  2019-11-19|112000|           332000|\n",
      "|          7| Grace|        HR|  2016-08-30| 64000|            64000|\n",
      "|          8|  Hank|        HR|  2018-05-20| 66000|           130000|\n",
      "|          9|   Ivy|        HR|  2020-02-14| 64000|           194000|\n",
      "|         18|  Rita|        HR|  2021-09-01| 66000|           260000|\n",
      "|          4| David|        IT|  2017-11-01| 98000|            98000|\n",
      "|          5|   Eva|        IT|  2018-12-24|102000|           200000|\n",
      "|          6| Frank|        IT|  2019-04-10| 98000|           298000|\n",
      "|         17| Quinn|        IT|  2021-06-18|102000|           400000|\n",
      "|         19|   Sam| Marketing|  2016-05-05| 92000|            92000|\n",
      "|         11| Karen| Marketing|  2017-03-22| 89000|           181000|\n",
      "|         10|  Jack| Marketing|  2019-07-07| 87000|           268000|\n",
      "|         12|   Leo| Marketing|  2020-09-30| 87000|           355000|\n",
      "|          1| Alice|     Sales|  2018-01-15| 72000|            72000|\n",
      "|          2|   Bob|     Sales|  2019-03-12| 68000|           140000|\n",
      "|         20|  Tara|     Sales|  2019-03-12| 75000|           215000|\n",
      "|          3| Carol|     Sales|  2020-06-05| 72000|           287000|\n",
      "|         16|  Pete|     Sales|  2021-01-03| 68000|           355000|\n",
      "+-----------+------+----------+------------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cumulative salary sum per department ordered by joining date.\n",
    "\n",
    "dept_wise_joining = Window.partitionBy(\"department\").orderBy(col(\"joining_date\").asc()).rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "cumulative_salary = emp.withColumn(\"cumulative_salary\", _sum(\"salary\").over(dept_wise_joining))\n",
    "\n",
    "cumulative_salary.select(\"employee_id\",\"name\",\"department\",\"joining_date\",\"salary\",\"cumulative_salary\").orderBy(\"department\",\"joining_date\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e0fc1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------+-----------------+--------------------------+\n",
      "|  name|department|joining_date|performance_score|moving_average_performance|\n",
      "+------+----------+------------+-----------------+--------------------------+\n",
      "|  Maya|   Finance|  2016-01-10|              4.8|                       4.5|\n",
      "|  Nate|   Finance|  2018-10-12|              4.2|                       4.6|\n",
      "|Olivia|   Finance|  2019-11-19|              4.8|                       4.5|\n",
      "| Grace|        HR|  2016-08-30|              3.2|                       3.4|\n",
      "|  Hank|        HR|  2018-05-20|              3.6|                      3.57|\n",
      "|   Ivy|        HR|  2020-02-14|              3.9|                      3.67|\n",
      "|  Rita|        HR|  2021-09-01|              3.5|                       3.7|\n",
      "| David|        IT|  2017-11-01|              4.9|                       4.8|\n",
      "|   Eva|        IT|  2018-12-24|              4.7|                       4.7|\n",
      "| Frank|        IT|  2019-04-10|              4.5|                      4.53|\n",
      "| Quinn|        IT|  2021-06-18|              4.4|                      4.45|\n",
      "|   Sam| Marketing|  2016-05-05|              4.9|                      4.75|\n",
      "+------+----------+------------+-----------------+--------------------------+\n",
      "only showing top 12 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "mov_avg = Window.partitionBy(\"department\").orderBy(\"joining_date\").rowsBetween(-1,1)\n",
    "\n",
    "emp_mov_avg = emp.withColumn(\"moving_average_performance\", round((_avg(\"performance_score\")).over(mov_avg), 2))\n",
    "\n",
    "emp_mov_avg.select(\"name\",\"department\",\"joining_date\",\"performance_score\",\"moving_average_performance\")\\\n",
    "        .orderBy(\"department\",\"joining_date\").show(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5c5412cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----------+------+------+\n",
      "|order_id|region|order_date|amount|sum_7d|\n",
      "+--------+------+----------+------+------+\n",
      "|    1004|  East|2021-01-07| 450.0| 450.0|\n",
      "|    1005|  East|2021-01-08| 200.0| 650.0|\n",
      "|    1010|  East|2021-01-11| 700.0|1350.0|\n",
      "|    1014|  East|2021-01-15| 250.0|1150.0|\n",
      "|    1018|  East|2021-01-19| 130.0| 380.0|\n",
      "|    1001| North|2021-01-02| 250.0| 250.0|\n",
      "|    1002| North|2021-01-05| 120.0| 370.0|\n",
      "|    1007| North|2021-01-09| 320.0| 690.0|\n",
      "|    1012| North|2021-01-13|  90.0| 410.0|\n",
      "|    1016| North|2021-01-17|  75.0| 165.0|\n",
      "|    1020| North|2021-01-21| 310.0| 385.0|\n",
      "|    1003| South|2021-01-03| 300.0| 300.0|\n",
      "+--------+------+----------+------+------+\n",
      "only showing top 12 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "orders_ts = orders.withColumn(\"order_ts\", unix_timestamp(col(\"order_date\").cast(\"timestamp\")))\n",
    "\n",
    "region_time = Window.partitionBy(\"region\").orderBy(\"order_ts\").rangeBetween(-7*24*3600, 0)\n",
    "orders_7d = orders_ts.withColumn(\"sum_7d\", _sum(\"amount\").over(region_time))\n",
    "orders_7d.select(\"order_id\",\"region\",\"order_date\",\"amount\",\"sum_7d\").orderBy(\"region\",\"order_date\").show(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9628e5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------+----------+------+\n",
      "|order_id|customer|region|order_date|amount|\n",
      "+--------+--------+------+----------+------+\n",
      "|    1001|   Alice| North|2021-01-02| 250.0|\n",
      "|    1002|     Bob| North|2021-01-05| 120.0|\n",
      "|    1003|   Carol| South|2021-01-03| 300.0|\n",
      "|    1004|   David|  East|2021-01-07| 450.0|\n",
      "+--------+--------+------+----------+------+\n",
      "only showing top 4 rows\n"
     ]
    }
   ],
   "source": [
    "orders.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e4a0ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------+------------+\n",
      "|  name|department|salary|highest_paid|\n",
      "+------+----------+------+------------+\n",
      "|  Maya|   Finance|112000|           1|\n",
      "|Olivia|   Finance|112000|           2|\n",
      "|  Nate|   Finance|108000|           3|\n",
      "|  Hank|        HR| 66000|           1|\n",
      "|  Rita|        HR| 66000|           2|\n",
      "| Grace|        HR| 64000|           3|\n",
      "|   Ivy|        HR| 64000|           4|\n",
      "|   Eva|        IT|102000|           1|\n",
      "| Quinn|        IT|102000|           2|\n",
      "| David|        IT| 98000|           3|\n",
      "| Frank|        IT| 98000|           4|\n",
      "|   Sam| Marketing| 92000|           1|\n",
      "| Karen| Marketing| 89000|           2|\n",
      "|  Jack| Marketing| 87000|           3|\n",
      "|   Leo| Marketing| 87000|           4|\n",
      "|  Tara|     Sales| 75000|           1|\n",
      "| Alice|     Sales| 72000|           2|\n",
      "| Carol|     Sales| 72000|           3|\n",
      "|   Bob|     Sales| 68000|           4|\n",
      "|  Pete|     Sales| 68000|           5|\n",
      "+------+----------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top 2 highest-paid employees per department\n",
    "\n",
    "dept_wise = Window.partitionBy(\"department\").orderBy(col(\"salary\").desc())\n",
    "\n",
    "highest_paid = emp.withColumn(\"highest_paid\", row_number().over(dept_wise))\n",
    "\n",
    "highest_paid.select(\"name\",\"department\",\"salary\",\"highest_paid\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81116bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
